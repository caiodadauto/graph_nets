{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xUTIiPkb45xH",
    "outputId": "ac761e03-907b-4088-bf17-9832f56a8c51"
   },
   "outputs": [],
   "source": [
    "#@title ### Install the Graph Nets library on this Colaboratory runtime  { form-width: \"60%\", run: \"auto\"}\n",
    "#@markdown <br>1. Connect to a local or hosted Colaboratory runtime by clicking the **Connect** button at the top-right.<br>2. Choose \"Yes\" below to install the Graph Nets library on the runtime machine with:<br>\n",
    "\n",
    "install_graph_nets_library = \"Yes\"  #@param [\"Yes\", \"No\"]\n",
    "install_pybrite = \"Yes\"  #@param [\"Yes\", \"No\"]\n",
    "install_tf_gpu = \"No\"  #@param [\"Yes\", \"No\"]\n",
    "\n",
    "print(\"Installing Tensorflow library with:\")\n",
    "print(\"  $ pip install tensorflow=='r1.14'\\n\")\n",
    "print(\"Output message from command:\\n\")\n",
    "#!pip uninstall tensorflow tensorflow-gpu\n",
    "!pip install tensorflow==\"1.14.0\"\n",
    "\n",
    "if install_graph_nets_library.lower() == \"yes\":\n",
    "    print(\"Installing variation of Graph Nets library from github with:\")\n",
    "    print(\"  $ git clone https://github.com/caiodadauto/graph_nets\\n\")\n",
    "    print(\"  $ pip install graph_nets/\\n\")\n",
    "    print(\"Output message from command:\\n\")\n",
    "    !git clone https://github.com/caiodadauto/graph_nets\n",
    "    !pip install graph_nets/\n",
    "else:\n",
    "    print(\"Skipping installation of Graph Nets library\")\n",
    "    \n",
    "if install_tf_gpu.lower() == \"yes\":\n",
    "    print(\"Installing Tensorflow GPU library with:\")\n",
    "    print(\"  $ pip install tensorflow-gpu\\n\")\n",
    "    print(\"Output message from command:\\n\")\n",
    "    !pip install tensorflow-gpu\n",
    "else:\n",
    "    print(\"Skipping installation of Tensorflow GPU library\")\n",
    "\n",
    "if install_pybrite.lower() == \"yes\":\n",
    "    print(\"Installing pybrite from github with:\")\n",
    "    print(\"  $ git clone --single-branch --branch colab https://github.com/caiodadauto/pybrite.git\\n\")\n",
    "    print(\"  $ pip install pybrite/pybrite/\")\n",
    "    print(\"Output message from command:\\n\")\n",
    "    !git clone --single-branch --branch colab https://github.com/caiodadauto/pybrite.git\n",
    "    !pip install pybrite/pybrite/\n",
    "else:\n",
    "    print(\"Skipping installation of Pybrite library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "rY_mZraR45xT",
    "outputId": "54fe8db2-ebfe-4aff-ccf2-681e0e3d29a2"
   },
   "outputs": [],
   "source": [
    "#@title Imports  { form-width: \"30%\" }\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pybrite\n",
    "from graph_nets import graphs\n",
    "from graph_nets import blocks\n",
    "from graph_nets import modules\n",
    "from graph_nets import utils_np\n",
    "from graph_nets import utils_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "ckW56Fik45xd",
    "outputId": "4b9d12a3-22db-42af-e13b-5e2894e9e120"
   },
   "outputs": [],
   "source": [
    "#@title Set google drive access  { form-width: \"30%\" }\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Dad6eRI45xk"
   },
   "outputs": [],
   "source": [
    "#@title Set Seed, Layers Number and their Size { form-width: \"30%\" }\n",
    "\n",
    "SEED = 2  #@param{type: 'integer'}\n",
    "NUM_LAYERS = 2  #@param{type: 'integer'}\n",
    "LATENT_SIZE = 16  #@param{type: 'integer'}\n",
    "TEST_LOCAL_STATS = False\n",
    "SCALE = True\n",
    "DRIVE_PATH = \"/content/gdrive/My Drive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eEsbweX45xr"
   },
   "outputs": [],
   "source": [
    "#@title Helper Functions: Tensorflow Integration { form-width: \"30%\" }\n",
    "\n",
    "def create_placeholders(batch_generator):\n",
    "    # Create some example data for inspecting the vector sizes.\n",
    "    input_graphs, target_graphs, _ = next(batch_generator)\n",
    "    input_ph = utils_tf.placeholders_from_networkxs(input_graphs)\n",
    "    target_ph = utils_tf.placeholders_from_networkxs(target_graphs)\n",
    "    \n",
    "    dtype = tf.as_dtype(utils_np.networkxs_to_graphs_tuple(target_graphs).edges.dtype)\n",
    "    weight_ph = tf.placeholder(dtype, name=\"loss_weights\")\n",
    "    is_training_ph = tf.placeholder(tf.bool, name=\"training_flag\")\n",
    "    return input_ph, target_ph, weight_ph, is_training_ph\n",
    "\n",
    "def create_feed_dict(batch_generator, is_training, weights, input_ph, target_ph, is_training_ph, weight_ph):\n",
    "    inputs, targets, pos = next(batch_generator)\n",
    "    input_graphs = utils_np.networkxs_to_graphs_tuple(inputs)\n",
    "    target_graphs = utils_np.networkxs_to_graphs_tuple(targets)\n",
    "    \n",
    "    if weights[0] != 1 or weights[1] != 1:\n",
    "        batch_weights = np.ones(target_graphs.edges.shape[0])\n",
    "        target_args = np.argmax(target_graphs.edges, axis=-1)\n",
    "        batch_weights[target_args == 0] *= weights[0]\n",
    "        batch_weights[target_args == 1] *= weights[1]\n",
    "    else:\n",
    "        batch_weights = 1\n",
    "    \n",
    "    feed_dict = {input_ph: input_graphs, target_ph: target_graphs, is_training_ph: is_training, weight_ph: batch_weights}\n",
    "    return feed_dict, pos\n",
    "\n",
    "def compute_accuracy(target, output, distribution=False):\n",
    "    acc_all = []\n",
    "    solved_all = []\n",
    "    acc_true_all = []\n",
    "    acc_false_all = []\n",
    "    solved_true_all = []\n",
    "    solved_false_all = []\n",
    "    \n",
    "    tg_dict = utils_np.graphs_tuple_to_data_dicts(target)\n",
    "    out_dict = utils_np.graphs_tuple_to_data_dicts(output)\n",
    "    for tg_graph, out_graph in zip(tg_dict, out_dict):\n",
    "        expect = np.argmax(tg_graph[\"edges\"], axis=-1)\n",
    "        predict = np.argmax(out_graph[\"edges\"], axis=-1)\n",
    "        true_mask = np.ma.masked_equal(expect, 1).mask\n",
    "        false_mask = np.ma.masked_equal(expect, 0).mask\n",
    "\n",
    "        acc = (expect == predict)\n",
    "        acc_true = acc[true_mask]\n",
    "        acc_false = acc[false_mask]\n",
    "\n",
    "        solved = np.all(acc)\n",
    "        solved_true = np.all(acc_true)\n",
    "        solved_false = np.all(acc_false)\n",
    "\n",
    "        acc_all.append(np.mean(acc))\n",
    "        acc_true_all.append(np.mean(acc_true))\n",
    "        acc_false_all.append(np.mean(acc_false))\n",
    "        \n",
    "        solved_all.append(solved)\n",
    "        solved_true_all.append(solved_true)\n",
    "        solved_false_all.append(solved_false)\n",
    "    acc_all = np.stack(acc_all)\n",
    "    acc_true_all = np.stack(acc_true_all)\n",
    "    acc_false_all = np.stack(acc_false_all)\n",
    "\n",
    "    solved_all = np.stack(solved_all)\n",
    "    solved_true_all = np.stack(solved_true_all)\n",
    "    solved_false_all = np.stack(solved_false_all)\n",
    "    if not distribution:\n",
    "        acc_all = np.mean(acc_all)\n",
    "        acc_true_all = np.mean(acc_true_all)\n",
    "        acc_false_all = np.mean(acc_false_all)\n",
    "\n",
    "        solved_all = np.mean(solved_all)\n",
    "        solved_true_all = np.mean(solved_true_all)\n",
    "        solved_false_all = np.mean(solved_false_all)\n",
    "    return acc_all, solved_all, acc_true_all, solved_true_all, acc_false_all, solved_false_all\n",
    "\n",
    "def get_generator_path_metrics(inputs, targets, outputs):\n",
    "    out_dicts = utils_np.graphs_tuple_to_data_dicts(outputs)\n",
    "    in_dicts = utils_np.graphs_tuple_to_data_dicts(inputs)\n",
    "    tg_dicts = utils_np.graphs_tuple_to_data_dicts(targets)\n",
    "\n",
    "    def softmax_prob(x):  # pylint: disable=redefined-outer-name\n",
    "        e = np.exp(x)\n",
    "        return e / np.sum(e, axis=-1, keepdims=True)\n",
    "    \n",
    "    n_graphs = len(tg_dicts)\n",
    "    for tg_graph, out_graph, in_graph, idx_graph in zip(tg_dicts, out_dicts, in_dicts, range(n_graphs)):\n",
    "        n_node = out_graph[\"n_node\"]\n",
    "        tg_graph_dist = tg_graph[\"nodes\"][:,0]\n",
    "        tg_graph_hops = tg_graph[\"nodes\"][:,1]\n",
    "        out_graph_dist = np.zeros_like(tg_graph_dist)\n",
    "        out_graph_hops = np.zeros_like(tg_graph_dist)\n",
    "        end_node = np.argwhere(tg_graph_dist == 0).reshape(1)[0]\n",
    "        for node in range(n_node):\n",
    "            hops = 0\n",
    "            strength = 0\n",
    "            start = node\n",
    "            sender = None\n",
    "            reachable = True\n",
    "            path = np.zeros(n_node, dtype=np.bool)\n",
    "            while start != end_node:\n",
    "                path[start] = True\n",
    "                start_edges_idx = np.argwhere(out_graph[\"senders\"] == start).reshape(-1,)\n",
    "                receivers = out_graph[\"receivers\"][start_edges_idx]\n",
    "                start_edges = out_graph[\"edges\"][start_edges_idx]\n",
    "                edges_prob = softmax_prob(start_edges)\n",
    "                \n",
    "                remove_sender = (receivers != sender) if sender else np.ones_like(receivers, dtype=np.bool)\n",
    "                routing_links = edges_prob[remove_sender, 0] < edges_prob[remove_sender, 1]\n",
    "\n",
    "                if not np.any(routing_links):\n",
    "                    routing_links = ~routing_links\n",
    "                    edge_forward_idx = np.argmin(edges_prob[remove_sender, 0] - edges_prob[remove_sender, 1])\n",
    "                else:\n",
    "                    edge_forward_idx = np.argmax(edges_prob[remove_sender][routing_links][:, -1])\n",
    "\n",
    "                if edge_forward_idx.size > 1:\n",
    "                    print(\"\\nMore than one max prob\\n\")\n",
    "\n",
    "                sender = start\n",
    "                start = receivers[remove_sender][routing_links][edge_forward_idx]\n",
    "                \n",
    "                if path[start]:\n",
    "                    reachable = False\n",
    "                    break\n",
    "                    \n",
    "                hops += 1\n",
    "                strength += in_graph[\"edges\"][start_edges_idx][remove_sender][routing_links][edge_forward_idx][0]\n",
    "            if reachable:\n",
    "                out_graph_dist[node] = strength\n",
    "                out_graph_hops[node] = hops\n",
    "        out_graph_hops = np.delete(out_graph_hops, end_node)\n",
    "        out_graph_dist = np.delete(out_graph_dist, end_node)\n",
    "        tg_graph_hops = np.delete(tg_graph_hops, end_node)\n",
    "        tg_graph_dist = np.delete(tg_graph_dist, end_node)\n",
    "        idx_non_zero = np.flatnonzero(out_graph_hops)\n",
    "        unreachable_p =  1 - idx_non_zero.size / out_graph_dist.size\n",
    "        if idx_non_zero.size > 0:\n",
    "            diff_dist = (np.abs(out_graph_dist[idx_non_zero] - tg_graph_dist[idx_non_zero]))\n",
    "            diff_hops = (np.abs(out_graph_hops[idx_non_zero] - tg_graph_hops[idx_non_zero]))\n",
    "            yield (diff_dist, diff_hops, unreachable_p)\n",
    "        else:\n",
    "            yield (None, None, unreachable_p)\n",
    "\n",
    "def aggregator_path_metrics(inputs, targets, outputs, distribution=False):\n",
    "    n_graphs = targets.n_node.size\n",
    "    idx_graph = 0\n",
    "    none_idx = []\n",
    "    hist_hops = []\n",
    "    hist_dist = []\n",
    "    batch_max_dist_diff = np.zeros(n_graphs)\n",
    "    batch_min_dist_diff = np.zeros(n_graphs)\n",
    "    batch_avg_dist_diff = np.zeros(n_graphs)\n",
    "    batch_max_hops_diff = np.zeros(n_graphs)\n",
    "    batch_min_hops_diff = np.zeros(n_graphs)\n",
    "    batch_avg_hops_diff = np.zeros(n_graphs)\n",
    "    batch_unreachable_p = np.zeros(n_graphs)\n",
    "    metrics_graph_generator = get_generator_path_metrics(inputs, targets, outputs)\n",
    "    for diff_dist, diff_hops, unreachable_p in metrics_graph_generator:\n",
    "        batch_unreachable_p[idx_graph] = unreachable_p\n",
    "        \n",
    "        if np.any(diff_dist == None):\n",
    "            none_idx.append(idx_graph)\n",
    "        else:\n",
    "            batch_max_dist_diff[idx_graph] = np.max(diff_dist)\n",
    "            batch_min_dist_diff[idx_graph] = np.min(diff_dist)\n",
    "            batch_avg_dist_diff[idx_graph] = np.mean(diff_dist)\n",
    "            batch_max_hops_diff[idx_graph] = np.max(diff_hops)\n",
    "            batch_min_hops_diff[idx_graph] = np.min(diff_hops)\n",
    "            batch_avg_hops_diff[idx_graph] = np.mean(diff_hops)\n",
    "            if distribution:\n",
    "                hist_hops.append(diff_hops)\n",
    "                hist_dist.append(diff_dist)\n",
    "        idx_graph += 1\n",
    "    batch_max_dist_diff = np.delete(batch_max_dist_diff, none_idx)\n",
    "    batch_min_dist_diff = np.delete(batch_min_dist_diff, none_idx)\n",
    "    batch_avg_dist_diff = np.delete(batch_avg_dist_diff, none_idx)\n",
    "    batch_max_hops_diff = np.delete(batch_max_hops_diff, none_idx)\n",
    "    batch_min_hops_diff = np.delete(batch_min_hops_diff, none_idx)\n",
    "    batch_avg_hops_diff = np.delete(batch_avg_hops_diff, none_idx)\n",
    "    if not distribution:\n",
    "        return dict(avg_batch_max_dist_diff=np.mean(batch_max_dist_diff) if batch_max_dist_diff.size else np.infty,\n",
    "                    avg_batch_min_dist_diff=np.mean(batch_min_dist_diff) if batch_min_dist_diff.size else np.infty,\n",
    "                    avg_batch_avg_dist_diff=np.mean(batch_avg_dist_diff) if batch_avg_dist_diff.size else np.infty,\n",
    "                    avg_batch_max_hops_diff=np.mean(batch_max_hops_diff) if batch_max_hops_diff.size else np.infty,\n",
    "                    avg_batch_min_hops_diff=np.mean(batch_min_hops_diff) if batch_min_hops_diff.size else np.infty,\n",
    "                    avg_batch_avg_hops_diff=np.mean(batch_avg_hops_diff) if batch_avg_hops_diff.size else np.infty,\n",
    "                    max_batch_unreachable_p=np.max(batch_unreachable_p),\n",
    "                    min_batch_unreachable_p=np.min(batch_unreachable_p),\n",
    "                    avg_batch_unreachable_p=np.mean(batch_unreachable_p))\n",
    "    else:\n",
    "        return {\"percentage of unreachable paths\":batch_unreachable_p, \"difference of hops\":np.concatenate(hist_hops), \"difference of strength\":np.concatenate(hist_dist)}\n",
    "\n",
    "def create_loss_ops(target_op, output_ops, weight):\n",
    "    loss_ops = [\n",
    "        tf.losses.softmax_cross_entropy(target_op.edges, output_op.edges, weights=weight)\n",
    "        for output_op in output_ops\n",
    "    ]\n",
    "    return loss_ops\n",
    "\n",
    "def make_all_runnable_in_session(*args):\n",
    "    \"\"\"Lets an iterable of TF graphs be output from a session as NP graphs.\"\"\"\n",
    "    return [utils_tf.make_runnable_in_session(a) for a in args]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mPE4S4Mf45xw"
   },
   "outputs": [],
   "source": [
    "#@title Helper Functions: Create Layers { form-width: \"30%\" }\n",
    "\n",
    "class LeakyReluMLP(snt.AbstractModule):\n",
    "    def __init__(self,\n",
    "                 hidden_size,\n",
    "                 n_layers,\n",
    "                 name=\"LeakyReluNormMLP\"):\n",
    "        super(LeakyReluMLP, self).__init__(name=name)\n",
    "        self._n_layers = n_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        with self._enter_variable_scope():\n",
    "            self._linear_layers = []\n",
    "            for _ in range(self._n_layers):\n",
    "                self._linear_layers.append(snt.Linear(self._hidden_size))\n",
    "            \n",
    "    def _build(self, inputs, is_training):\n",
    "        outputs_op = inputs\n",
    "        for linear in self._linear_layers:\n",
    "            outputs_op = linear(outputs_op)\n",
    "            outputs_op = tf.nn.leaky_relu(outputs_op, alpha=0.05)\n",
    "        return outputs_op\n",
    "\n",
    "\n",
    "class LeakyReluNormMLP(snt.AbstractModule):\n",
    "    def __init__(self,\n",
    "                 hidden_size,\n",
    "                 n_layers,\n",
    "                 name=\"LeakyReluNormMLP\"):\n",
    "        super(LeakyReluNormMLP, self).__init__(name=name)\n",
    "        self._n_layers = n_layers\n",
    "        self._hidden_size = hidden_size\n",
    "        with self._enter_variable_scope():\n",
    "            self._linear_layers = []\n",
    "            self._bn_layers = []\n",
    "            for _ in range(self._n_layers):\n",
    "                self._linear_layers.append(snt.Linear(self._hidden_size))\n",
    "                self._bn_layers.append(snt.BatchNorm(scale=SCALE))\n",
    "            \n",
    "    def _build(self, inputs, is_training):\n",
    "        outputs_op = inputs\n",
    "        for linear, bn in zip(self._linear_layers, self._bn_layers):\n",
    "            outputs_op = linear(outputs_op)\n",
    "            outputs_op = tf.nn.leaky_relu(outputs_op, alpha=0.05)\n",
    "            outputs_op = bn(outputs_op, is_training=is_training, test_local_stats=TEST_LOCAL_STATS)\n",
    "        return outputs_op\n",
    "    \n",
    "class LeakyReluNormGRU(snt.AbstractModule):\n",
    "    def __init__(self,\n",
    "                 hidden_size,\n",
    "                 recurrent_dropout=0.75,\n",
    "                 name=\"LeakyReluNormGRU\"):\n",
    "        super(LeakyReluNormGRU, self).__init__(name=name)\n",
    "        self._hidden_size = hidden_size\n",
    "        with self._enter_variable_scope():\n",
    "            self._gru = snt.GRU(self._hidden_size)\n",
    "            self._dropout_gru = snt.python.modules.gated_rnn.RecurrentDropoutWrapper(self._gru, recurrent_dropout)\n",
    "            self._batch_norm = snt.BatchNorm(scale=SCALE)\n",
    "    \n",
    "    def get_initial_state(self, batch_size, dtype=tf.float64):\n",
    "        return self._dropout_gru.initial_state(batch_size, dtype=dtype)\n",
    "    \n",
    "    def _build(self, inputs, prev_states, is_training):\n",
    "        def true_fn():\n",
    "            return self._dropout_gru(inputs, prev_states)\n",
    "        \n",
    "        def false_fn():\n",
    "            o, ns = self._gru(inputs, prev_states[0])\n",
    "            ns = (ns, [tf.ones_like(ns, name=\"FoolMask\")])\n",
    "            return o, ns\n",
    "        \n",
    "        outputs_op, next_states = tf.cond(is_training, true_fn=true_fn, false_fn=false_fn)\n",
    "        outputs_op = tf.nn.leaky_relu(outputs_op, alpha=0.05)\n",
    "        outputs_op = self._batch_norm(outputs_op, is_training=is_training, test_local_stats=TEST_LOCAL_STATS)\n",
    "        return outputs_op, next_states\n",
    "\n",
    "def make_gru_model(size=LATENT_SIZE):\n",
    "    \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
    "\n",
    "    The parameters of each new MLP are not shared with others generated by\n",
    "    this function.\n",
    "\n",
    "    Returns:\n",
    "    A Sonnet module which contains the MLP and LayerNorm.\n",
    "    \"\"\"\n",
    "    return LeakyReluNormGRU(size)\n",
    "\n",
    "def make_mlp_model(size=LATENT_SIZE, n_layers=NUM_LAYERS, model=LeakyReluNormMLP):\n",
    "    \"\"\"Instantiates a new MLP, followed by LayerNorm.\n",
    "\n",
    "    The parameters of each new MLP are not shared with others generated by\n",
    "    this function.\n",
    "\n",
    "    Returns:\n",
    "    A Sonnet module which contains the MLP and LayerNorm.\n",
    "    \"\"\"\n",
    "    return model(size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6efgaON45x2"
   },
   "outputs": [],
   "source": [
    "#@title Helper Classes: Modules to Integrate the Encode-Process-Decode Architecture { form-width: \"30%\" }\n",
    "\n",
    "class LocalRoutingNetwork(snt.AbstractModule):\n",
    "    \"\"\"Implement neural network to deal with local routing table lookup.\n",
    "    \n",
    "    See net.in.tum.de/fileadmin/bibtex/publications/papers/geyer2018bigdama.pdf\n",
    "    figure 2 for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 output_size,\n",
    "                 query_model_fn=make_mlp_model,\n",
    "                 weight_model_fn=make_mlp_model,\n",
    "                 n_heads=3,\n",
    "                 name=\"LocalRoutingNetwork\"):\n",
    "        super(LocalRoutingNetwork, self).__init__(name=name)\n",
    "        #self._multihead_weight = []\n",
    "        with self._enter_variable_scope():\n",
    "            self._query_model = query_model_fn()\n",
    "            self._logist_routing = snt.Linear(output_size, name=\"routing_logist_layer\")\n",
    "            #for _ in range(n_heads):\n",
    "            #    self._multihead_weight.append(weight_model_fn())\n",
    "            self._model_weight = weight_model_fn()\n",
    "        \n",
    "    def _build(self, inputs, **kwargs):\n",
    "        query_output = self._query_model(inputs.globals, **kwargs)\n",
    "        queries_output = utils_tf.repeat(query_output, inputs.n_edge)\n",
    "        point_wise = tf.multiply(queries_output, inputs.edges)\n",
    "        senders_feature = tf.gather(inputs.nodes, inputs.senders)\n",
    "        weight_input = tf.concat([senders_feature, point_wise], -1)\n",
    "        #weights = []\n",
    "        #for model in self._multihead_weight:\n",
    "        #    weight_output = self._logist_routing(model(weight_input, **kwargs))\n",
    "        #    weights.append(self._unsorted_segment_softmax(\n",
    "        #        weight_output, inputs.senders, tf.reduce_sum(inputs.n_node)))\n",
    "        #output_edges = tf.reduce_mean(tf.stack(weights), axis=0)\n",
    "        output_edges = self._logist_routing(self._model_weight(weight_input, **kwargs))\n",
    "        return inputs.replace(edges=output_edges)\n",
    "    \n",
    "    def _unsorted_segment_softmax(self, x, idx, n_idx):\n",
    "        op1 = tf.exp(x)\n",
    "        op2 = tf.unsorted_segment_sum(op1, idx, n_idx)\n",
    "        op3 = tf.reduce_sum(op2, -1, keepdims=True)\n",
    "        op4 = tf.gather(op3, idx)\n",
    "        op5 = tf.divide(op1, op4)\n",
    "        return op5\n",
    "    \n",
    "class MLPGraphIndependent(snt.AbstractModule):\n",
    "    \"\"\"GraphIndependent with MLP edge, node, and global models.\"\"\"\n",
    "\n",
    "    def __init__(self, name=\"MLPGraphIndependent\"):\n",
    "        super(MLPGraphIndependent, self).__init__(name=name)\n",
    "        with self._enter_variable_scope():\n",
    "            self._network = modules.GraphIndependent(\n",
    "                edge_model_fn=make_mlp_model,\n",
    "                node_model_fn=make_mlp_model,\n",
    "                global_model_fn=None)\n",
    "\n",
    "    def _build(self, inputs, **kwargs):\n",
    "        return self._network(inputs, **kwargs)\n",
    "\n",
    "class GraphGatedNonLocalNetwork(snt.AbstractModule):\n",
    "    \"\"\"Implementation of Non-Local Neural Network. Basically, there is not used\n",
    "    global features, only ones of the nodes and edges.\n",
    "\n",
    "    See arxiv.org/abs/1806.01261 Figura 4d for more deatais about network,\n",
    "    beyond there is made the update on edge's features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 gate_recurrent_model_fn=make_gru_model,\n",
    "                 bias_shape=[LATENT_SIZE * 3],\n",
    "                 reducer=tf.unsorted_segment_sum,\n",
    "                 name=\"GraphGatedNonLocalNetwork\"):\n",
    "        \"\"\"Initializes the GraphGatedNonLocalNetwork module.\n",
    "\n",
    "        Args:\n",
    "            edge_model_fn: A callable that will be passed to EdgeBlock to perform\n",
    "                per-edge computations. The callable must return a Sonnet module (or\n",
    "                equivalent; see EdgeBlock for details).\n",
    "            node_model_fn: A callable that will be passed to NodeBlock to perform\n",
    "                per-node computations. The callable must return a Sonnet module (or\n",
    "                equivalent; see NodeBlock for details).\n",
    "            reducer: Reducer to be used by NodeBlock to aggregate nodes and edges.\n",
    "                Defaults to tf.unsorted_segment_sum.\n",
    "            name: The module name.\n",
    "        \"\"\"\n",
    "        super(GraphGatedNonLocalNetwork, self).__init__(name=name)\n",
    "\n",
    "        with self._enter_variable_scope():\n",
    "            self._edge_block = blocks.GatedEdgeBlock(\n",
    "                gate_recurrent_model_fn=gate_recurrent_model_fn,\n",
    "                use_edges=True,\n",
    "                use_receiver_nodes=True,\n",
    "                use_sender_nodes=True,\n",
    "                use_globals=False\n",
    "            )\n",
    "            self._node_block = blocks.GatedNodeBlock(\n",
    "                gate_recurrent_model_fn=gate_recurrent_model_fn,\n",
    "                bias_shape=bias_shape,\n",
    "                use_received_edges=True,\n",
    "                use_sent_edges=False,\n",
    "                use_nodes=True,\n",
    "                use_globals=False\n",
    "            )\n",
    "\n",
    "    def reset_state(self, edge_batch_size,  node_batch_size, edge_state=None, node_state=None):\n",
    "        self._edge_block.reset_state(edge_batch_size, state=edge_state)\n",
    "        self._node_block.reset_state(node_batch_size, state=node_state)\n",
    "            \n",
    "    def _build(self, graph, **kwargs):\n",
    "        \"\"\"Connects the GraphGatedNonLocalNetwork.\n",
    "\n",
    "        Args:\n",
    "          graph: A `graphs.GraphsTuple` containing `Tensor`s. The features of\n",
    "            each nodes and edges of `graph` should be concatenable on the last dimension.\n",
    "\n",
    "        Returns:\n",
    "          An output `graphs.GraphsTuple` with updated edges, nodes and globals.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self._node_block(self._edge_block(graph, **kwargs), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qV1OsgBc45x6"
   },
   "outputs": [],
   "source": [
    "#@title Encode-Process-Decode Architecture { form-width: \"30%\" }\n",
    "\n",
    "class EncodeProcessDecode(snt.AbstractModule):\n",
    "    \"\"\"Full encode-process-decode model.\n",
    "\n",
    "      The model we explore includes three components:\n",
    "      - An \"Encoder\" graph net, which independently encodes the edge, node, and\n",
    "        global attributes (does not compute relations etc.).\n",
    "      - A \"Core\" graph net, which performs N rounds of processing (message-passing)\n",
    "        steps. The input to the Core is the concatenation of the Encoder's output\n",
    "        and the previous output of the Core (labeled \"Hidden(t)\" below, where \"t\" is\n",
    "        the processing step).\n",
    "      - A \"Decoder\" graph net, which independently decodes the edge, node, and\n",
    "        global attributes (does not compute relations etc.), on each message-passing\n",
    "        step.\n",
    "        \n",
    "                            h(t)        h(t + 1)\n",
    "                *---------*  |  *------*    |  *---------*    *---------*\n",
    "                |         |  |  |      |    |  |         |    |         |\n",
    "      Input --->| Encoder |  *->| Core |----*->| Decoder |--->| Lookup  |--->Output(t)\n",
    "                |         |---->|      |       |         |    |         |\n",
    "                *---------*     *------*       *---------*    *---------*\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, edge_output_size, name=\"EncodeProcessDecode\"):\n",
    "        super(EncodeProcessDecode, self).__init__(name=name)\n",
    "        with self._enter_variable_scope():\n",
    "            self._encoder = MLPGraphIndependent()\n",
    "            self._core = GraphGatedNonLocalNetwork()\n",
    "            #self._decoder = MLPGraphIndependent()\n",
    "            self._lookup = LocalRoutingNetwork(edge_output_size)\n",
    "\n",
    "    def _build(self, input_op, num_processing_steps, is_training):\n",
    "        latent0 = self._encoder(input_op, is_training=is_training)\n",
    "        latent = latent0\n",
    "        output_ops = []\n",
    "        node_batch_size = tf.reduce_sum(latent.n_node)\n",
    "        edge_batch_size = tf.reduce_sum(latent.n_edge)\n",
    "        self._core.reset_state(edge_batch_size, node_batch_size)\n",
    "        for _ in range(num_processing_steps):\n",
    "            core_input = utils_tf.concat([latent0, latent], axis=1, use_global=False)\n",
    "            latent = self._core(core_input, is_training=is_training)\n",
    "            #decoded_op = self._decoder(latent, is_training=is_training)\n",
    "            output_ops.append(self._lookup(latent, is_training=is_training))\n",
    "        return output_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gr7InKF145yA"
   },
   "source": [
    "#  Set up model training and evaluation\n",
    "\n",
    "The model we explore includes three components:\n",
    "- An \"Encoder\" graph net, which independently encodes the edge, node, and\n",
    "    global attributes (does not compute relations etc.).\n",
    "- A \"Core\" graph net, which performs N rounds of processing (message-passing)\n",
    "    steps. The input to the Core is the concatenation of the Encoder's output\n",
    "    and the previous output of the Core. Moreover the core uses a recurrent layer to\n",
    "    process the node features.\n",
    "- A \"Decoder\" graph net, which decodes the edge attributes to the output shape,\n",
    "    which is the dimension of the hot-one vector that represents with a edge (link) is\n",
    "    used to achieve a previous determined end node. This computation is made on each\n",
    "    message-passing step.\n",
    "        \n",
    "The model is trained by supervised learning. Input graphs are procedurally generated, and output\n",
    "graphs have the same structure with the edges of the shortest path labeled (using 2-element 1-hot\n",
    "vectors).\n",
    "\n",
    "The training loss is computed on the output of each processing step. The reason for this is to\n",
    "encourage the model to try to solve the problem in as few steps as possible. It also helps make\n",
    "the output of intermediate steps more interpretable.\n",
    "\n",
    "There's no need for a separate evaluate dataset because the inputs are never repeated, so the training\n",
    "loss is the measure of performance on graphs from the input distribution.\n",
    "\n",
    "We also evaluate how well the models generalize to graphs which are up to twice as large as those on which\n",
    "it was trained. The loss is computed only on the final processing step.\n",
    "\n",
    "Variables with the suffix _tr are training parameters, and variables with the suffix _ge are test/generalization\n",
    "parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EErmLmKV45yD",
    "outputId": "9fd67d92-184a-4355-af86-3ff4ea214404"
   },
   "outputs": [],
   "source": [
    "#@title Set up model { form-width: \"30%\" }\n",
    "\n",
    "tf.set_random_seed(SEED)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "random_state = np.random.RandomState(seed=SEED)\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 20 #@param{type: 'integer'}\n",
    "num_processing_steps_ge = 20 #@param{type: 'integer'}\n",
    "\n",
    "# Data / training parameters.\n",
    "num_training_iterations = 50000 #@param{type: 'integer'}\n",
    "\n",
    "batch_size_tr = 32 #@param{type: 'integer'}\n",
    "batch_size_ge = 32 #@param{type: 'integer'}\n",
    "\n",
    "# Number of nodes per graph sampled uniformly from this range.\n",
    "min_num_nodes_tr = 8 #@param{type: 'integer'}\n",
    "max_num_nodes_tr = 20 #@param{type: 'integer'}\n",
    "min_num_nodes_ge = 16 #@param{type: 'integer'}\n",
    "max_num_nodes_ge = 33 #@param{type: 'integer'}\n",
    "num_nodes_min_max_tr = (min_num_nodes_tr, max_num_nodes_tr)\n",
    "num_nodes_min_max_ge = (min_num_nodes_ge, max_num_nodes_ge)\n",
    "\n",
    "batch_generator_tr = pybrite.graph_batch_generator(\n",
    "    batch_size_tr, num_nodes_min_max_tr, random_state=random_state)#, input_fields=dict(node=(\"pos\",)), global_field=\"pos\")\n",
    "batch_generator_ge = pybrite.graph_batch_generator(\n",
    "    batch_size_ge, num_nodes_min_max_ge, random_state=random_state)#, input_fields=dict(node=(\"pos\",)), global_field=\"pos\")\n",
    "\n",
    "# Data.\n",
    "# Input and target placeholders.\n",
    "input_ph, target_ph, weight_ph, is_training_ph = create_placeholders(batch_generator_tr)\n",
    "\n",
    "# Connect the data to the model.\n",
    "# Instantiate the model.\n",
    "model = EncodeProcessDecode(edge_output_size=2)\n",
    "# A list of outputs, one per processing step.\n",
    "output_ops_tr = model(input_ph, num_processing_steps_tr, is_training_ph)\n",
    "output_ops_ge = model(input_ph, num_processing_steps_ge, is_training_ph)\n",
    "\n",
    "# Training loss.\n",
    "loss_ops_tr = create_loss_ops(target_ph, output_ops_tr, weight_ph)\n",
    "# Loss across processing steps.\n",
    "loss_op_tr = sum(loss_ops_tr) / num_processing_steps_tr\n",
    "# Test/generalization loss.\n",
    "loss_ops_ge = create_loss_ops(target_ph, output_ops_ge, weight_ph)\n",
    "loss_op_ge = loss_ops_ge[-1]  # Loss from final processing step.\n",
    "\n",
    "# Optimizer.\n",
    "## Fixed\n",
    "#learning_rate = 1e-3\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "#step_op = optimizer.minimize(loss_op_tr)\n",
    "## Dynamically TF Way\n",
    "starter_learning_rate = 1e-2\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "#learning_rate = tf.train.cosine_decay_restarts(starter_learning_rate, global_step, first_decay_steps=1000, m_mul=0.99, alpha=5e-6)\n",
    "learning_rate = tf.train.polynomial_decay(starter_learning_rate, global_step, decay_steps=15000, end_learning_rate=1e-4, power=3)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)#tf.train.MomentumOptimizer(learning_rate, momentum=0.6)\n",
    "step_op = optimizer.minimize(loss_op_tr, global_step=global_step)\n",
    "\n",
    "# Lets an iterable of TF graphs be output from a session as NP graphs.\n",
    "input_ph, target_ph = make_all_runnable_in_session(input_ph, target_ph)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZNG5-0IL45yK",
    "outputId": "3ae41b0e-83b4-46f2-b245-40420310ad7c"
   },
   "outputs": [],
   "source": [
    "#@title Reset session  { form-width: \"30%\" }\n",
    "\n",
    "# This cell resets the Tensorflow session, but keeps the same computational\n",
    "# graph.\n",
    "\n",
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "last_iteration = 18000 #@param{type: 'integer'}\n",
    "logged_iterations = []\n",
    "losses_tr = []\n",
    "corrects_tr = []\n",
    "solveds_tr = []\n",
    "losses_ge = []\n",
    "corrects_ge = []\n",
    "solveds_ge = []\n",
    "\n",
    "restore_path = os.path.join(DRIVE_PATH, \"TF-GNN-W-Sess/Sess %s/\"%last_iteration)\n",
    "if os.path.isdir(restore_path):\n",
    "    saver.restore(sess, os.path.join(restore_path, \"dm.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "ypocNxGZ45yR",
    "outputId": "041918e5-d584-4183-a6b7-09646dbd3994"
   },
   "outputs": [],
   "source": [
    "#@title Run training  { form-width: \"30%\" }\n",
    "\n",
    "# You can interrupt this cell's training loop at any time, and visualize the\n",
    "# intermediate results by running the next cell (below). You can then resume\n",
    "# training by simply executing this cell again.\n",
    "\n",
    "# How much time between logging and printing the current results.\n",
    "log_every_seconds = 20\n",
    "\n",
    "print(\"Iteration,Elapsed Time (s),Loss Tr,Loss Ge,\"\n",
    "      \"Accuracy Tr,Solved Tr,Accuracy Ge,Solved Ge,\"\n",
    "      \"True Accuracy Tr,True Solved Tr,True Accuracy Ge,True Solved Ge,\"\n",
    "      \"False Accuracy Tr,False Solved Tr,False Accuracy Ge,False Solved Ge,\"\n",
    "      \"Avg Batch Max Dist Diff Tr,Avg Batch Min Dist Diff Tr,Avg Batch Avg Dist Diff Tr,\"\n",
    "      \"Avg Batch Max Hops Diff Tr,Avg Batch Min Hops Diff Tr,Avg Batch Avg Hops Diff Tr,\"\n",
    "      \"Max Batch unreachable Tr,Min Batch unreachable Tr,Avg Batch unreachable Tr,\"\n",
    "      \"Avg Batch Max Dist Diff Ge,Avg Batch Min Dist Diff Ge,Avg Batch Avg Dist Diff Ge,\"\n",
    "      \"Avg Batch Max Hops Diff Ge,Avg Batch Min Hops Diff Ge,Avg Batch Avg Hops Diff Ge,\"\n",
    "      \"Max Batch unreachable Ge,Min Batch unreachable Ge,Avg Batch unreachable Ge\")\n",
    "\n",
    "start_time = time.time()\n",
    "last_log_time = start_time\n",
    "\n",
    "for iteration in range(last_iteration, num_training_iterations):\n",
    "    last_iteration = iteration\n",
    "    feed_dict, _ = create_feed_dict(batch_generator_tr, True, [.3, 1], input_ph, target_ph, is_training_ph, weight_ph)\n",
    "    train_values = sess.run({\n",
    "        \"step\": step_op,\n",
    "        \"input\": input_ph,\n",
    "        \"target\": target_ph,\n",
    "        \"loss\": loss_op_tr,\n",
    "        \"outputs\": output_ops_tr\n",
    "    },\n",
    "        feed_dict=feed_dict)\n",
    "    \n",
    "    the_time = time.time()\n",
    "    elapsed_since_last_log = the_time - last_log_time\n",
    "    if (elapsed_since_last_log > log_every_seconds) or ((iteration + 1) % 500 == 0):\n",
    "        last_log_time = the_time\n",
    "        feed_dict, _ = create_feed_dict(batch_generator_ge, False, [.3, 1], input_ph, target_ph, is_training_ph, weight_ph)\n",
    "        test_values = sess.run({\n",
    "            \"input\": input_ph,\n",
    "            \"target\": target_ph,\n",
    "            \"loss\": loss_op_ge,\n",
    "            \"outputs\": output_ops_ge\n",
    "        },\n",
    "            feed_dict=feed_dict)\n",
    "        \n",
    "        tr_path_metrics = aggregator_path_metrics(train_values[\"input\"], train_values[\"target\"], train_values[\"outputs\"][-1])\n",
    "        ge_path_metrics = aggregator_path_metrics(test_values[\"input\"], test_values[\"target\"], test_values[\"outputs\"][-1])\n",
    "\n",
    "        correct_tr, solved_tr, true_correct_tr, true_solved_tr, false_correct_tr, false_solved_tr = compute_accuracy(\n",
    "            train_values[\"target\"], train_values[\"outputs\"][-1])\n",
    "        correct_ge, solved_ge, true_correct_ge, true_solved_ge, false_correct_ge, false_solved_ge = compute_accuracy(\n",
    "            test_values[\"target\"], test_values[\"outputs\"][-1])\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        losses_tr.append(train_values[\"loss\"])\n",
    "        corrects_tr.append(correct_tr)\n",
    "        solveds_tr.append(solved_tr)\n",
    "        losses_ge.append(test_values[\"loss\"])\n",
    "        corrects_ge.append(correct_ge)\n",
    "        solveds_ge.append(solved_ge)\n",
    "        logged_iterations.append(iteration)\n",
    "        if (iteration + 1) % 500 == 0:\n",
    "            sess_path = os.path.join(DRIVE_PATH, \"TF-GNN-W-Sess/Sess %s/\"%(iteration + 1))\n",
    "            if not os.path.isdir(sess_path):\n",
    "                os.makedirs(sess_path)\n",
    "            _ = saver.save(sess, os.path.join(sess_path, \"dm.ckpt\"))\n",
    "        print(\"{:05d}, {:.1f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, \"\n",
    "              \"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, \"\n",
    "              \"{:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}, {:.4f}\".format(\n",
    "                  iteration, elapsed, train_values[\"loss\"], test_values[\"loss\"], correct_tr, solved_tr, correct_ge, solved_ge,\n",
    "                  true_correct_tr, true_solved_tr, true_correct_ge, true_solved_ge,\n",
    "                  false_correct_tr, false_solved_tr, false_correct_ge, false_solved_ge,\n",
    "                  tr_path_metrics[\"avg_batch_max_dist_diff\"], tr_path_metrics[\"avg_batch_min_dist_diff\"], tr_path_metrics[\"avg_batch_avg_dist_diff\"],\n",
    "                  tr_path_metrics[\"avg_batch_max_hops_diff\"], tr_path_metrics[\"avg_batch_min_hops_diff\"], tr_path_metrics[\"avg_batch_avg_hops_diff\"],\n",
    "                  tr_path_metrics[\"max_batch_unreachable_p\"], tr_path_metrics[\"min_batch_unreachable_p\"], tr_path_metrics[\"avg_batch_unreachable_p\"],\n",
    "                  ge_path_metrics[\"avg_batch_max_dist_diff\"], ge_path_metrics[\"avg_batch_min_dist_diff\"], ge_path_metrics[\"avg_batch_avg_dist_diff\"],\n",
    "                  ge_path_metrics[\"avg_batch_max_hops_diff\"], ge_path_metrics[\"avg_batch_min_hops_diff\"], ge_path_metrics[\"avg_batch_avg_hops_diff\"],\n",
    "                  ge_path_metrics[\"max_batch_unreachable_p\"], ge_path_metrics[\"min_batch_unreachable_p\"], ge_path_metrics[\"avg_batch_unreachable_p\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzBBexoWwEM8"
   },
   "outputs": [],
   "source": [
    "#@title Set Environment to See Distribution{ form-width: \"30%\" }\n",
    "#@markdown <br>Some parameters in the TF sesseion will be redefined to take measures of the path metrics in a batch.\n",
    "\n",
    "tf.set_random_seed(SEED)\n",
    "tf.res2et_default_graph()\n",
    "\n",
    "random_state = np.random.RandomState(seed=SEED)\n",
    "\n",
    "# Model parameters.\n",
    "# Number of processing (message-passing) steps.\n",
    "num_processing_steps_tr = 30 #@param{type: 'integer'}\n",
    "num_processing_steps_ge = 50 #@param{type: 'integer'}\n",
    "\n",
    "batch_size_tr = 1000 #@param{type: 'integer'}\n",
    "batch_size_ge = 1000 #@param{type: 'integer'}\n",
    "\n",
    "# Number of nodes per graph sampled uniformly from this range.\n",
    "min_num_nodes_tr = 15 #@param{type: 'integer'}\n",
    "max_num_nodes_tr = 30 #@param{type: 'integer'}\n",
    "min_num_nodes_ge = 25 #@param{type: 'integer'}\n",
    "max_num_nodes_ge = 50 #@param{type: 'integer'}\n",
    "num_nodes_min_max_tr = (min_num_nodes_tr, max_num_nodes_tr)\n",
    "num_nodes_min_max_ge = (min_num_nodes_ge, max_num_nodes_ge)\n",
    "\n",
    "batch_generator_tr = pybrite.graph_batch_generator(\n",
    "    batch_size_tr, num_nodes_min_max_tr, random_state=random_state)\n",
    "batch_generator_ge = pybrite.graph_batch_generator(\n",
    "    batch_size_ge, num_nodes_min_max_ge, random_state=random_state)\n",
    "\n",
    "# Data.\n",
    "# Input and target placeholders.\n",
    "input_ph, target_ph = create_placeholders(batch_generator_tr)\n",
    "\n",
    "# Connect the data to the model.\n",
    "# Instantiate the model.\n",
    "model = EncodeProcessDecode(edge_output_size=2)\n",
    "# A list of outputs, one per processing step.\n",
    "output_ops_tr = model(input_ph, num_processing_steps_tr)\n",
    "output_ops_ge = model(input_ph, num_processing_steps_ge)\n",
    "\n",
    "# Lets an iterable of TF graphs be output from a session as NP graphs.\n",
    "input_ph, target_ph = make_all_runnable_in_session(input_ph, target_ph)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XI19U8zZ45yX"
   },
   "outputs": [],
   "source": [
    "#@title Reset Session and Restore one from Drive{ form-width: \"30%\" }\n",
    "\n",
    "try:\n",
    "    sess.close()\n",
    "except NameError:\n",
    "    pass\n",
    "sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "\n",
    "last_iteration = 9500 #@param{type: 'integer'}\n",
    "\n",
    "restore_path = os.path.join(DRIVE_PATH, \"TF-GNN-Sess/Sess %s/\"%last_iteration)\n",
    "try:\n",
    "    saver.restore(sess, os.path.join(restore_path, \"dm.ckpt\"))\n",
    "except:\n",
    "    print(\"There are not any saved session for this last iteration.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZAAgPHEwyrS"
   },
   "outputs": [],
   "source": [
    "feed_dict_tr = create_feed_dict(batch_generator_tr, input_ph, target_ph)\n",
    "train_values = sess.run({\n",
    "    \"input\": input_ph,\n",
    "    \"target\": target_ph,\n",
    "    \"outputs\": output_ops_tr\n",
    "},\n",
    "    feed_dict=feed_dict_tr)\n",
    "\n",
    "feed_dict_ge = create_feed_dict(batch_generator_ge, input_ph, target_ph)\n",
    "test_values = sess.run({\n",
    "    \"input\": input_ph,\n",
    "    \"target\": target_ph,\n",
    "    \"outputs\": output_ops_ge\n",
    "},\n",
    "    feed_dict=feed_dict_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9NJ3IjuAP3s8"
   },
   "outputs": [],
   "source": [
    "graph_idx = 0\n",
    "hist_path = os.path.join(DRIVE_PATH, \"Histograms/\")\n",
    "metrics_graph_generator = get_generator_path_metrics(train_values[\"input\"], train_values[\"target\"], train_values[\"outputs\"][-1])\n",
    "for diff_dist, diff_hops, unreachable_p in metrics_graph_generator:\n",
    "    file_path = os.path.join(hist_path, \"Tr/%s - %.3f.csv\"%(graph_idx, unreachable_p))\n",
    "    if not np.any(diff_dist == None):\n",
    "        df = pd.DataFrame(np.array([diff_dist, diff_hops]).T, columns=[\"Distance Diff\", \"Hops Diff\"])\n",
    "        df.to_csv(file_path, index=False)\n",
    "    graph_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EniRxg3gTC_c"
   },
   "outputs": [],
   "source": [
    "graph_idx = 0\n",
    "hist_path = os.path.join(DRIVE_PATH, \"Histograms/\")\n",
    "metrics_graph_generator = get_generator_path_metrics(test_values[\"input\"], test_values[\"target\"], test_values[\"outputs\"][-1])\n",
    "for diff_dist, diff_hops, unreachable_p in metrics_graph_generator:\n",
    "    file_path = os.path.join(hist_path, \"Ge/%s - %.3f.csv\"%(graph_idx, unreachable_p))\n",
    "    if not np.any(diff_dist == None):\n",
    "        df = pd.DataFrame(np.array([diff_dist, diff_hops]).T, columns=[\"Distance Diff\", \"Hops Diff\"])\n",
    "        df.to_csv(file_path, index=False)\n",
    "    graph_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVxTEt3JkE9T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "routing_class.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
